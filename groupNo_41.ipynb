{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lFrMBq7iooFV","executionInfo":{"status":"ok","timestamp":1729605831913,"user_tz":-330,"elapsed":9933,"user":{"displayName":"Prabhakar Pandey","userId":"09476072549464523908"}},"outputId":"05473336-0b27-4bf9-e82e-545839fe0a1b"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["!unzip /content/drive/MyDrive/mini-project-1.zip >> /dev/null"],"metadata":{"id":"6dKx9XSIfDdW","executionInfo":{"status":"ok","timestamp":1729605855348,"user_tz":-330,"elapsed":19858,"user":{"displayName":"Prabhakar Pandey","userId":"09476072549464523908"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"4b307af5-56ab-4635-df1c-b13724ad0337"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["replace mini-project-1/datasets/train/train_feature.npz? [y]es, [n]o, [A]ll, [N]one, [r]ename: "]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.svm import SVC\n","from sklearn.preprocessing import StandardScaler\n","from tensorflow.keras.models import load_model\n","import joblib  # For loading the model\n","import pickle  # For loading the tokenizer\n","\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","\n","\n","# =========================\n","# 1. Predictions from SVM Model for Text Sequences\n","# =========================\n","\n","# Load the text sequence datasets\n","test_textseq = pd.read_csv('/content/mini-project-1/datasets/test/test_text_seq.csv')  # Ensure the file name matches\n","\n","# Convert the text sequence to individual digits (splitting each string into list of integers)\n","X_test_seq = test_textseq['input_str'].apply(lambda x: [int(char) for char in x]).tolist()\n","X_test_seq = pd.DataFrame(X_test_seq)\n","\n","# Load the saved encoder\n","encoder = joblib.load('/content/mini-project-1/saved-models/onehot_encoder.pkl')\n","\n","# One-Hot Encoding\n","X_test_encoded = encoder.transform(X_test_seq)  # Use transform instead of fit_transform\n","\n","# Load the saved SVM model\n","loaded_model_seq = joblib.load('/content/mini-project-1/saved-models/best_svm_model.pkl')\n","\n","# Predict on the test dataset\n","y_pred_seq = loaded_model_seq.predict(X_test_encoded)\n","\n","# Save predictions to a text file\n","with open(\"pred_text.txt\", \"w\") as f:\n","    for i, pred in enumerate(y_pred_seq):\n","        f.write(f\"{pred}\\n\")\n","\n","print(\"Text sequence predictions saved to 'pred_text.txt'.\")\n","\n","\n","# =========================\n","# 2. Predictions from Keras Model for Emoticons\n","# =========================\n","\n","# Load the test dataset for emoticons\n","test_emoticon_df = pd.read_csv(\"/content/mini-project-1/datasets/test/test_emoticon.csv\")\n","test_emoticon_X = test_emoticon_df['input_emoticon'].tolist()\n","\n","# Load the saved Keras model\n","model_emoticon = load_model(\"/content/mini-project-1/saved-models/dense_model.h5\")\n","\n","# Load the tokenizer\n","with open(\"/content/mini-project-1/saved-models/tokenizer.pkl\", \"rb\") as f:\n","    tokenizer = pickle.load(f)\n","\n","# Prepare test data for predictions\n","test_sequences = tokenizer.texts_to_sequences(test_emoticon_X)\n","max_len = model_emoticon.input_shape[1]  # Get the correct max_len from the model\n","test_padded = pad_sequences(test_sequences, maxlen=max_len, padding='post')\n","\n","# Make predictions\n","predictions_emoticon = (model_emoticon.predict(test_padded) > 0.5).astype(int)  # Assuming binary classification\n","\n","# Save predictions to a text file\n","with open(\"pred_emoticon.txt\", \"w\") as f:\n","    for emoticon, pred in zip(test_emoticon_X, predictions_emoticon):\n","        f.write(f\"{pred[0]}\\n\")\n","\n","print(\"Emoticon predictions saved to 'pred_emoticon.txt'.\")\n","\n","\n","# =========================\n","# 3. Predictions from FeatureModel for Features\n","# =========================\n","\n","# Load the trained model and scaler for feature data\n","model_feature = joblib.load(\"/content/mini-project-1/saved-models/svm_model.joblib\")\n","scaler = joblib.load(\"/content/mini-project-1/saved-models/scaler.joblib\")\n","\n","# Load the test dataset for features\n","test_feat_X = np.load(\"/content/mini-project-1/datasets/test/test_feature.npz\", allow_pickle=True)['features']  # Update this path as necessary\n","\n","# FeatureModel class for prediction\n","class FeatureModel:\n","    def __init__(self, model=None, scaler=None):\n","        self.model = model\n","        self.scaler = scaler\n","\n","    def predict(self, X):\n","        X = X.reshape(X.shape[0], -1)\n","        X = self.scaler.transform(X)\n","        return self.model.predict(X)\n","\n","# Initialize the FeatureModel with the loaded model and scaler\n","feature_model = FeatureModel(model=model_feature, scaler=scaler)\n","\n","# Make predictions for test data\n","predictions_feature = feature_model.predict(test_feat_X)\n","\n","# Save predictions to a text file\n","with open(\"pred_feat.txt\", \"w\") as f:\n","    for i, pred in enumerate(predictions_feature):\n","        f.write(f\"{pred}\\n\")\n","\n","print(\"Feature data predictions saved to 'pred_feat.txt'.\")\n","\n","\n","# =========================\n","# 4. Predictions from Combined Model\n","# =========================\n","\n","# Load the saved combined model\n","model_combined = tf.keras.models.load_model('/content/mini-project-1/saved-models/combined_model.h5')\n","\n","# Load the test data\n","test_emoticon_df = pd.read_csv('/content/mini-project-1/datasets/test/test_emoticon.csv')\n","test_embedding_df = pd.read_csv('/content/mini-project-1/datasets/test/test_text_seq.csv')\n","\n","# Prepare test data\n","test_emoticon_X = test_emoticon_df['input_emoticon'].tolist()\n","\n","# Load text data\n","test_text_X = np.load('/content/mini-project-1/datasets/test/test_feature.npz')['features']\n","\n","# Convert NumPy arrays to lists of strings\n","test_text_X = [' '.join(map(str, sublist)) if isinstance(sublist, list) else str(sublist) for sublist in test_text_X]\n","\n","# Initialize tokenizer with the same setup used during training\n","train_emoticon_df = pd.read_csv('/content/mini-project-1/datasets/train/train_emoticon.csv')\n","train_embedding_df = pd.read_csv('/content/mini-project-1/datasets/train/train_text_seq.csv')\n","\n","train_emoticon_X = train_emoticon_df['input_emoticon'].tolist()\n","train_text_X = np.load('/content/mini-project-1/datasets/train/train_feature.npz')['features']\n","train_text_X = [' '.join(map(str, sublist)) if isinstance(sublist, list) else str(sublist) for sublist in train_text_X]\n","\n","# Initialize tokenizer and fit on training data (emoticons + text)\n","tokenizer = Tokenizer(char_level=True)\n","tokenizer.fit_on_texts(train_emoticon_X + train_text_X)\n","\n","# Pad sequences for emoticons (using the same max_len_emoticon as during training)\n","test_emoticon_sequences = tokenizer.texts_to_sequences(test_emoticon_X)\n","max_len_emoticon = max(len(seq) for seq in tokenizer.texts_to_sequences(train_emoticon_X))  # Use training max length\n","test_emoticon_padded = pad_sequences(test_emoticon_sequences, maxlen=max_len_emoticon, padding='post')\n","\n","# Pad sequences for text (using the same max_len_text as during training)\n","test_text_sequences = tokenizer.texts_to_sequences(test_text_X)\n","max_len_text = max(len(seq) for seq in tokenizer.texts_to_sequences(train_text_X))  # Use training max length\n","test_text_padded = pad_sequences(test_text_sequences, maxlen=max_len_text, padding='post')\n","\n","# Check input shapes to ensure they match\n","print(f\"Test Emoticon Shape: {test_emoticon_padded.shape}, Test Text Shape: {test_text_padded.shape}\")\n","\n","# Make predictions on the test dataset\n","predictions_combined = model_combined.predict([test_emoticon_padded, test_text_padded])\n","\n","# Output predictions - using a threshold of 0.5 for binary classification\n","predicted_labels_combined = [1 if pred >= 0.5 else 0 for pred in predictions_combined]\n","\n","\n","# Save combined predictions to a text file\n","with open(\"pred_combined.txt\", \"w\") as f:\n","    for pred in predicted_labels_combined:\n","        f.write(f\"{pred}\\n\")\n","\n","print(\"Combined predictions saved to 'pred_combined.txt'.\")\n"],"metadata":{"id":"O-R1NDnuia6u","colab":{"base_uri":"https://localhost:8080/","height":445},"executionInfo":{"status":"error","timestamp":1729599071939,"user_tz":-330,"elapsed":57355,"user":{"displayName":"Tsewang Namgail","userId":"05300373250283332603"}},"outputId":"e43bdc0e-e23e-4948-d7e8-e1d657d24372"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Text sequence predictions saved to 'pred_text.txt'.\n","\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","Emoticon predictions saved to 'pred_emoticon.txt'.\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-e85385ae0e7e>\u001b[0m in \u001b[0;36m<cell line: 103>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;31m# Make predictions for test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m \u001b[0mpredictions_feature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_feat_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;31m# Save predictions to a text file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-9-e85385ae0e7e>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;31m# Initialize the FeatureModel with the loaded model and scaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    811\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 813\u001b[0;31m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    814\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    428\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_for_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse_predict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dense_predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_dense_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36m_dense_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    447\u001b[0m         \u001b[0msvm_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLIBSVM_IMPL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_impl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m         return libsvm.predict(\n\u001b[0m\u001b[1;32m    450\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupport_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.svm import SVC\n","from sklearn.preprocessing import StandardScaler\n","from tensorflow.keras.models import load_model\n","import joblib  # For loading the model\n","import pickle  # For loading the tokenizer\n","\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","\n","\n","# =========================\n","# 1. Predictions from SVM Model for Text Sequences\n","# =========================\n","\n","# Load the text sequence datasets\n","test_textseq = pd.read_csv('/content/mini-project-1/datasets/test/test_text_seq.csv')  # Ensure the file name matches\n","\n","# Convert the text sequence to individual digits (splitting each string into list of integers)\n","X_test_seq = test_textseq['input_str'].apply(lambda x: [int(char) for char in x]).tolist()\n","X_test_seq = pd.DataFrame(X_test_seq)\n","\n","# Load the saved encoder\n","encoder = joblib.load('/content/mini-project-1/saved-models/onehot_encoder.pkl')\n","\n","# One-Hot Encoding\n","X_test_encoded = encoder.transform(X_test_seq)  # Use transform instead of fit_transform\n","\n","# Load the saved SVM model\n","loaded_model_seq = joblib.load('/content/mini-project-1/saved-models/best_svm_model.pkl')\n","\n","# Predict on the test dataset\n","y_pred_seq = loaded_model_seq.predict(X_test_encoded)\n","\n","# Save predictions to a text file\n","with open(\"pred_text.txt\", \"w\") as f:\n","    for i, pred in enumerate(y_pred_seq):\n","        f.write(f\"{pred}\\n\")\n","\n","print(\"Text sequence predictions saved to 'pred_text.txt'.\")\n","\n","\n","# =========================\n","# 2. Predictions from Keras Model for Emoticons\n","# =========================\n","\n","# Load the test dataset for emoticons\n","test_emoticon_df = pd.read_csv(\"/content/mini-project-1/datasets/test/test_emoticon.csv\")\n","test_emoticon_X = test_emoticon_df['input_emoticon'].tolist()\n","\n","# Load the saved Keras model\n","model_emoticon = load_model(\"/content/mini-project-1/saved-models/dense_model.h5\")\n","\n","# Load the tokenizer\n","with open(\"/content/mini-project-1/saved-models/tokenizer.pkl\", \"rb\") as f:\n","    tokenizer = pickle.load(f)\n","\n","# Prepare test data for predictions\n","test_sequences = tokenizer.texts_to_sequences(test_emoticon_X)\n","max_len = model_emoticon.input_shape[1]  # Get the correct max_len from the model\n","test_padded = pad_sequences(test_sequences, maxlen=max_len, padding='post')\n","\n","# Make predictions\n","predictions_emoticon = (model_emoticon.predict(test_padded) > 0.5).astype(int)  # Assuming binary classification\n","\n","# Save predictions to a text file\n","with open(\"pred_emoticon.txt\", \"w\") as f:\n","    for emoticon, pred in zip(test_emoticon_X, predictions_emoticon):\n","        f.write(f\"{pred[0]}\\n\")\n","\n","print(\"Emoticon predictions saved to 'pred_emoticon.txt'.\")\n","\n","\n","# =========================\n","# 3. Predictions from FeatureModel for Features\n","# =========================\n","\n","# Load the trained model and scaler for feature data\n","model_feature = joblib.load(\"/content/mini-project-1/saved-models/svm_model.joblib\")\n","scaler = joblib.load(\"/content/mini-project-1/saved-models/scaler.joblib\")\n","\n","# Load the test dataset for features\n","test_feat_X = np.load(\"/content/mini-project-1/datasets/test/test_feature.npz\", allow_pickle=True)['features']  # Update this path as necessary\n","\n","# FeatureModel class for prediction\n","class FeatureModel:\n","    def __init__(self, model=None, scaler=None):\n","        self.model = model\n","        self.scaler = scaler\n","\n","    def predict(self, X):\n","        X = X.reshape(X.shape[0], -1)\n","        X = self.scaler.transform(X)\n","        return self.model.predict(X)\n","\n","# Initialize the FeatureModel with the loaded model and scaler\n","feature_model = FeatureModel(model=model_feature, scaler=scaler)\n","\n","# Make predictions for test data\n","predictions_feature = feature_model.predict(test_feat_X)\n","\n","# Save predictions to a text file\n","with open(\"pred_feat.txt\", \"w\") as f:\n","    for i, pred in enumerate(predictions_feature):\n","        f.write(f\"{pred}\\n\")\n","\n","print(\"Feature data predictions saved to 'pred_feat.txt'.\")\n","\n","\n","# =========================\n","# 4. Predictions from Combined Model\n","# =========================\n","\n","# Load the saved combined model\n","model_combined = tf.keras.models.load_model('/content/mini-project-1/saved-models/combined_model.h5')\n","\n","# Load the test data\n","test_emoticon_df = pd.read_csv('/content/mini-project-1/datasets/test/test_emoticon.csv')\n","test_embedding_df = pd.read_csv('/content/mini-project-1/datasets/test/test_text_seq.csv')\n","\n","# Prepare test data\n","test_emoticon_X = test_emoticon_df['input_emoticon'].tolist()\n","\n","# Load text data\n","test_text_X = np.load('/content/mini-project-1/datasets/test/test_feature.npz')['features']\n","\n","# Convert NumPy arrays to lists of strings\n","test_text_X = [' '.join(map(str, sublist)) if isinstance(sublist, list) else str(sublist) for sublist in test_text_X]\n","\n","# Initialize tokenizer with the same setup used during training\n","train_emoticon_df = pd.read_csv('/content/mini-project-1/datasets/train/train_emoticon.csv')\n","train_embedding_df = pd.read_csv('/content/mini-project-1/datasets/train/train_text_seq.csv')\n","\n","train_emoticon_X = train_emoticon_df['input_emoticon'].tolist()\n","train_text_X = np.load('/content/mini-project-1/datasets/train/train_feature.npz')['features']\n","train_text_X = [' '.join(map(str, sublist)) if isinstance(sublist, list) else str(sublist) for sublist in train_text_X]\n","\n","# Initialize tokenizer and fit on training data (emoticons + text)\n","tokenizer = Tokenizer(char_level=True)\n","tokenizer.fit_on_texts(train_emoticon_X + train_text_X)\n","\n","# Pad sequences for emoticons (using the same max_len_emoticon as during training)\n","test_emoticon_sequences = tokenizer.texts_to_sequences(test_emoticon_X)\n","max_len_emoticon = max(len(seq) for seq in tokenizer.texts_to_sequences(train_emoticon_X))  # Use training max length\n","test_emoticon_padded = pad_sequences(test_emoticon_sequences, maxlen=max_len_emoticon, padding='post')\n","\n","# Pad sequences for text (using the same max_len_text as during training)\n","test_text_sequences = tokenizer.texts_to_sequences(test_text_X)\n","max_len_text = max(len(seq) for seq in tokenizer.texts_to_sequences(train_text_X))  # Use training max length\n","test_text_padded = pad_sequences(test_text_sequences, maxlen=max_len_text, padding='post')\n","\n","# Check input shapes to ensure they match\n","print(f\"Test Emoticon Shape: {test_emoticon_padded.shape}, Test Text Shape: {test_text_padded.shape}\")\n","\n","# Make predictions on the test dataset\n","predictions_combined = model_combined.predict([test_emoticon_padded, test_text_padded])\n","\n","# Output predictions - using a threshold of 0.5 for binary classification\n","predicted_labels_combined = [1 if pred >= 0.5 else 0 for pred in predictions_combined]\n","\n","\n","# Save combined predictions to a text file\n","with open(\"pred_combined.txt\", \"w\") as f:\n","    for pred in predicted_labels_combined:\n","        f.write(f\"{pred}\\n\")\n","\n","print(\"Combined predictions saved to 'pred_combined.txt'.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":335},"id":"0xcCgBB8BhQT","executionInfo":{"status":"error","timestamp":1729605261136,"user_tz":-330,"elapsed":61498,"user":{"displayName":"Prabhakar Pandey","userId":"09476072549464523908"}},"outputId":"7dc97650-a05d-4902-fead-2a81ff58afcf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Text sequence predictions saved to 'pred_text.txt'.\n","\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","Emoticon predictions saved to 'pred_emoticon.txt'.\n","Feature data predictions saved to 'pred_feat.txt'.\n"]},{"output_type":"error","ename":"NameError","evalue":"name 'max_len_emoticon' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-6fbaf0f7d9bf>\u001b[0m in \u001b[0;36m<cell line: 150>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;31m# Pad emoticon data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0mtest_emoticon_sequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtexts_to_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_emoticon_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m \u001b[0mtest_emoticon_padded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_emoticon_sequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_len_emoticon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'post'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Use the max length used during training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;31m# Process the deep features (averaging)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'max_len_emoticon' is not defined"]}]},{"cell_type":"code","source":[],"metadata":{"id":"3gvRg2z8fAsw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.svm import SVC\n","from sklearn.preprocessing import StandardScaler\n","from tensorflow.keras.models import load_model\n","import joblib  # For loading the model\n","import pickle  # For loading the tokenizer\n","\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","\n","\n","# =========================\n","# 1. Predictions from SVM Model for Text Sequences\n","# =========================\n","\n","# Load the text sequence datasets\n","test_textseq = pd.read_csv('/content/mini-project-1/datasets/test/test_text_seq.csv')  # Ensure the file name matches\n","\n","# Convert the text sequence to individual digits (splitting each string into list of integers)\n","X_test_seq = test_textseq['input_str'].apply(lambda x: [int(char) for char in x]).tolist()\n","X_test_seq = pd.DataFrame(X_test_seq)\n","\n","# Load the saved encoder\n","encoder = joblib.load('/content/mini-project-1/saved-models/onehot_encoder.pkl')\n","\n","# One-Hot Encoding\n","X_test_encoded = encoder.transform(X_test_seq)  # Use transform instead of fit_transform\n","\n","# Load the saved SVM model\n","loaded_model_seq = joblib.load('/content/mini-project-1/saved-models/best_svm_model.pkl')\n","\n","# Predict on the test dataset\n","y_pred_seq = loaded_model_seq.predict(X_test_encoded)\n","\n","# Save predictions to a text file\n","with open(\"pred_text.txt\", \"w\") as f:\n","    for i, pred in enumerate(y_pred_seq):\n","        f.write(f\"{pred}\\n\")\n","\n","print(\"Text sequence predictions saved to 'pred_text.txt'.\")\n","\n","\n","# =========================\n","# 2. Predictions from Keras Model for Emoticons\n","# =========================\n","\n","# Load the test dataset for emoticons\n","test_emoticon_df = pd.read_csv(\"/content/mini-project-1/datasets/test/test_emoticon.csv\")\n","test_emoticon_X = test_emoticon_df['input_emoticon'].tolist()\n","\n","# Load the saved Keras model\n","model_emoticon = load_model(\"/content/mini-project-1/saved-models/dense_model.h5\")\n","\n","# Load the tokenizer\n","with open(\"/content/mini-project-1/saved-models/tokenizer.pkl\", \"rb\") as f:\n","    tokenizer = pickle.load(f)\n","\n","# Prepare test data for predictions\n","test_sequences = tokenizer.texts_to_sequences(test_emoticon_X)\n","max_len = model_emoticon.input_shape[1]  # Get the correct max_len from the model\n","test_padded = pad_sequences(test_sequences, maxlen=max_len, padding='post')\n","\n","# Make predictions\n","predictions_emoticon = (model_emoticon.predict(test_padded) > 0.5).astype(int)  # Assuming binary classification\n","\n","# Save predictions to a text file\n","with open(\"pred_emoticon.txt\", \"w\") as f:\n","    for emoticon, pred in zip(test_emoticon_X, predictions_emoticon):\n","        f.write(f\"{pred[0]}\\n\")\n","\n","print(\"Emoticon predictions saved to 'pred_emoticon.txt'.\")\n","\n","\n","# =========================\n","# 3. Predictions from FeatureModel for Features\n","# =========================\n","\n","# Load the trained model and scaler for feature data\n","model_feature = joblib.load(\"/content/mini-project-1/saved-models/svm_model.joblib\")\n","scaler = joblib.load(\"/content/mini-project-1/saved-models/scaler.joblib\")\n","\n","# Load the test dataset for features\n","test_feat_X = np.load(\"/content/mini-project-1/datasets/test/test_feature.npz\", allow_pickle=True)['features']  # Update this path as necessary\n","\n","# FeatureModel class for prediction\n","class FeatureModel:\n","    def __init__(self, model=None, scaler=None):\n","        self.model = model\n","        self.scaler = scaler\n","\n","    def predict(self, X):\n","        X = X.reshape(X.shape[0], -1)\n","        X = self.scaler.transform(X)\n","        return self.model.predict(X)\n","\n","# Initialize the FeatureModel with the loaded model and scaler\n","feature_model = FeatureModel(model=model_feature, scaler=scaler)\n","\n","# Make predictions for test data\n","predictions_feature = feature_model.predict(test_feat_X)\n","\n","# Save predictions to a text file\n","with open(\"pred_feat.txt\", \"w\") as f:\n","    for i, pred in enumerate(predictions_feature):\n","        f.write(f\"{pred}\\n\")\n","\n","print(\"Feature data predictions saved to 'pred_feat.txt'.\")\n","\n","\n","# =========================\n","# 4. Predictions from Combined Model\n","# =========================\n","\n","# Load the saved combined model\n","model_combined = tf.keras.models.load_model('/content/mini-project-1/saved-models/combined_model.h5')\n","\n","# Load the test data\n","test_emoticon_df = pd.read_csv('/content/mini-project-1/datasets/test/test_emoticon.csv')\n","test_embedding_df = pd.read_csv('/content/mini-project-1/datasets/test/test_text_seq.csv')\n","\n","# Prepare test data\n","test_emoticon_X = test_emoticon_df['input_emoticon'].tolist()\n","\n","# Load text data\n","test_text_X = np.load('/content/mini-project-1/datasets/test/test_feature.npz')['features']\n","\n","# Convert NumPy arrays to lists of strings\n","test_text_X = [' '.join(map(str, sublist)) if isinstance(sublist, list) else str(sublist) for sublist in test_text_X]\n","\n","# Initialize tokenizer with the same setup used during training\n","train_emoticon_df = pd.read_csv('/content/mini-project-1/datasets/train/train_emoticon.csv')\n","train_embedding_df = pd.read_csv('/content/mini-project-1/datasets/train/train_text_seq.csv')\n","\n","train_emoticon_X = train_emoticon_df['input_emoticon'].tolist()\n","train_text_X = np.load('/content/mini-project-1/datasets/train/train_feature.npz')['features']\n","train_text_X = [' '.join(map(str, sublist)) if isinstance(sublist, list) else str(sublist) for sublist in train_text_X]\n","\n","# Initialize tokenizer and fit on training data (emoticons + text)\n","tokenizer = Tokenizer(char_level=True)\n","tokenizer.fit_on_texts(train_emoticon_X + train_text_X)\n","\n","# Pad sequences for emoticons (using the same max_len_emoticon as during training)\n","test_emoticon_sequences = tokenizer.texts_to_sequences(test_emoticon_X)\n","max_len_emoticon = max(len(seq) for seq in tokenizer.texts_to_sequences(train_emoticon_X))  # Use training max length\n","test_emoticon_padded = pad_sequences(test_emoticon_sequences, maxlen=max_len_emoticon, padding='post')\n","\n","# Pad sequences for text (using the same max_len_text as during training)\n","test_text_sequences = tokenizer.texts_to_sequences(test_text_X)\n","max_len_text = max(len(seq) for seq in tokenizer.texts_to_sequences(train_text_X))  # Use training max length\n","test_text_padded = pad_sequences(test_text_sequences, maxlen=max_len_text, padding='post')\n","\n","# Check input shapes to ensure they match\n","print(f\"Test Emoticon Shape: {test_emoticon_padded.shape}, Test Text Shape: {test_text_padded.shape}\")\n","\n","# Make predictions on the test dataset\n","predictions_combined = model_combined.predict([test_emoticon_padded, test_text_padded])\n","\n","# Output predictions - using a threshold of 0.5 for binary classification\n","predicted_labels_combined = [1 if pred >= 0.5 else 0 for pred in predictions_combined]\n","\n","\n","# Save combined predictions to a text file\n","with open(\"pred_combined.txt\", \"w\") as f:\n","    for pred in predicted_labels_combined:\n","        f.write(f\"{pred}\\n\")\n","\n","print(\"Combined predictions saved to 'pred_combined.txt'.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T486cSQAi3Q9","executionInfo":{"status":"ok","timestamp":1729605972264,"user_tz":-330,"elapsed":76715,"user":{"displayName":"Prabhakar Pandey","userId":"09476072549464523908"}},"outputId":"5da518f7-fb12-4926-c746-1b094e3933fc"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Text sequence predictions saved to 'pred_text.txt'.\n","\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","Emoticon predictions saved to 'pred_emoticon.txt'.\n","Feature data predictions saved to 'pred_feat.txt'.\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Test Emoticon Shape: (2232, 13), Test Text Shape: (2232, 635)\n","\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 113ms/step\n","Combined predictions saved to 'pred_combined.txt'.\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"AwkfU_Ydi36W"},"execution_count":null,"outputs":[]}]}